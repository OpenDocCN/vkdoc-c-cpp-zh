# 15.解释者

解释器设计模式的目标是，你猜对了，解释输入，尤其是文本输入，尽管公平地说这真的无关紧要。解释器的概念与大学教授的编译理论和类似课程有很大联系。因为我们在这里没有足够的空间来深入研究不同类型的解析器的复杂性，所以本章的目的是简单地展示一些你可能想要解释的事情的例子。

这里有几个相当明显的例子:

*   像`42`或`1.234e12`这样的数字文字需要被解释为有效地存储在二进制中。在 C++中，这些操作通过 C APIs 如`atof()`以及更复杂的库如 Boost.LexicalCast 来实现
*   正则表达式帮助我们找到文本中的模式，但你需要认识到的是，正则表达式本质上是一种独立的、嵌入式的特定领域语言(DSL)。当然，在使用它们之前，必须对它们进行正确的解释。
*   任何结构化数据，无论是 CSV、XML、JSON 还是更复杂的数据，在使用之前都需要解释。
*   在解释器应用的顶峰，我们有完全成熟的编程语言。毕竟，像 C 或 Python 这样的语言的编译器或解释器在使某些东西可执行之前必须真正理解这种语言。

鉴于与口译有关的挑战的扩散和多样性，我们将简单地看一些例子。这些用来说明如何构建一个解释器:要么从零开始，要么利用一个在工业规模上帮助做这些事情的库。

## 数值表达式计算器

假设我们决定解析非常简单的数学表达式，比如 3+(5–4)，也就是说，我们将限制自己使用加法、减法和括号。我们想要一个程序，可以读取这样的表达式，当然，计算表达式的最终值。

我们将手工构建计算器，而不求助于任何解析框架。这应该有望突出解析文本输入所涉及的一些复杂性。

### 乐星

解释表达式的第一步称为词法分析，它涉及到将一系列字符转换成一系列标记。一个标记通常是一个基本的语法元素，我们应该以这样一个简单的序列结束。在我们的例子中，令牌可以是

*   整数
*   运算符(加号或减号)
*   左括号或右括号

因此，我们可以定义以下结构:

```
 1   struct Token
 2   {
 3     enum Type { integer, plus, minus, lparen, rparen } type;
 4     string text;
 5
 6     explicit Token(Type type, const string& text)
 7       : type{type}, text{text} {}
 8
 9     friend ostream& operator<<(ostream& os, const Token& obj)
10     {
11       return os << "`" << obj.text << "`";
12     }
13   };

```

你会注意到`Token`不是一个`enum`,因为除了类型之外，我们还想存储与这个令牌相关的文本，因为它并不总是预定义的。

现在，给定一个包含表达式的`std::string`，我们可以定义一个词法分析过程，将文本转换成`vector<Token>`:

```
 1   vector<Token> lex(const string& input)
 2   {
 3     vector<Token> result;
 4
 5     for (int i = 0; i < input.size(); ++i)
 6     {
 7       switch (input[i])
 8       {
 9       case '+':
10         result.push_back(Token{ Token::plus, "+" });
11         break;
12       case '-':
13         result.push_back(Token{ Token::minus, "-" });
14         break;
15       case '(':
16         result.push_back(Token{ Token::lparen, "(" });
17         break;
18       case ')':
19         result.push_back(Token{ Token::rparen, ")" });
20         break;
21       default:
22         // number ???
23       }
24     }
25   }

```

解析预定义的令牌很容易。事实上，我们本可以把它们作为`map<BinaryOperation, char>`来添加，以简化事情。但是解析一个数字并不容易。如果我们击中了 1，我们应该等待，看看下一个字符是什么。为此，我们定义了一个单独的例程:

```
 1   ostringstream buffer;
 2   buffer << input[i];
 3   for (int j = i + 1; j < input.size(); ++j)
 4   {
 5     if (isdigit(input[j]))
 6     {
 7       buffer << input[j];
 8       ++i;
 9     }
10     else

11     {
12       result.push_back(Token{ Token::integer, buffer.str() });
13       break;
14     }
15   }

```

本质上，当我们不断读取(抽取)数字时，我们将它们添加到缓冲区中。完成后，我们从整个缓冲区中创建一个`Token`，并将其添加到结果`vector`中。

### 从语法上分析

解析过程将一系列标记转换成有意义的、通常面向对象的结构。在顶部，拥有一个树的所有元素都实现的抽象父类型通常很有用:

```
1   struct Element
2   {
3     virtual int eval() const = 0;
4   };

```

类型的`eval()`函数计算这个元素的数值。接下来，我们可以创建一个元素来存储整数值(如 1、5 或 42):

```
1   struct Integer : Element
2   {
3     int value;
4
5     explicit Integer(const int value)
6       : value(value) {}
7
8     int eval() const override { return value; }
9   };

```

如果我们没有一个`Integer`，就必须有一个加法或者减法之类的运算。在我们的例子中，所有的操作都是二进制的，这意味着它们有两个部分。例如，我们模型中的`2+3`可以用伪代码表示为`BinaryOperation{Literal{2}, Literal{3}, addition}`:

```
 1   struct BinaryOperation : Element
 2   {
 3     enum Type { addition, subtraction } type;
 4     shared_ptr<Element> lhs, rhs;
 5
 6     int eval() const override

 7     {
 8       if (type == addition)
 9         return lhs->eval() + rhs->eval();
10       return lhs->eval() - rhs->eval();
11     }
12   };

```

注意，在前面，我使用了一个`enum`而不是一个`enum class`，这样我可以在后面写`BinaryOperation::addition`。

但是不管怎样，继续解析过程。我们需要做的就是将一系列的`Token`转换成一棵`Expression`的二叉树。从一开始，它看起来就像这样:

```
 1   shared_ptr<Element> parse(const vector<Token>& tokens)
 2   {
 3     auto result = make_unique<BinaryOperation>();
 4     bool have_lhs = false; // this will need some explaining :)
 5     for (size_t i = 0; i < tokens.size(); i++)
 6     {
 7       auto token = tokens[i];
 8       switch(token.type)
 9       {
10         // process each of the tokens in turn
11       }
12     }
13     return result;
14   }

```

从前面的代码中我们唯一需要讨论的是`have_lhs`变量。记住，你试图得到的是一棵树，在这棵树的根部，我们期待一个`BinaryExpression`,根据定义，它有左右两边。但是当我们在一个数字上时，我们怎么知道它是表达式的左边还是右边呢？是的，我们不知道，这就是为什么我们要追踪这个。

现在让我们一个案例一个案例地检查一下。首先，整数——它们直接映射到我们的`Integer`结构，所以我们所要做的就是将文本转换成数字。(顺便说一句，如果我们愿意，我们也可以在 lexing 阶段这样做。)

```
 1   case Token::integer:
 2   {
 3     int value = boost::lexical_cast<int>(token.text);
 4     auto integer = make_shared<Integer>(value);
 5     if (!have_lhs) {
 6       result->lhs = integer;
 7       have_lhs = true;
 8     }
 9     else result->rhs = integer;
10   }

```

`plus`和`minus`标记简单地决定了我们当前正在处理的操作的类型，所以它们很简单:

```
1   case Token::plus:
2     result->type = BinaryOperation::addition;
3     break;
4   case Token::minus:
5     result->type = BinaryOperation::subtraction;
6     break;

```

然后是左括号。是的，只有左边，我们在这个层次上没有明确地检测到右边的。基本上，这里的想法很简单:找到右括号(我现在忽略嵌套的括号)，取出整个子表达式，`parse()`递归地将它设置为我们当前正在处理的表达式的左边或右边:

```
 1   case Token::lparen:
 2   {
 3     int j = i;
 4     for (; j < tokens.size(); ++j)
 5       if (tokens[j].type == Token::rparen)
 6         break; // found it!
 7
 8     vector<Token> subexpression(&tokens[i + 1], &tokens[j]);
 9     auto element = parse(subexpression); // recursive call
10     if (!have_lhs)
11     {
12       result->lhs = element;
13       have_lhs = true;
14     }
15     else result->rhs = element;
16     i = j; // advance
17   }

```

在真实的场景中，您会希望这里有更多的安全特性:不仅处理嵌套括号(我认为这是必须的)，还处理缺少右括号的不正确表达式。如果真的不见了，你会怎么处理？抛出异常？尝试解析剩下的内容，并假设结束在最后？还有别的吗？所有这些问题都留给读者作为练习。

根据 C++本身的经验，我们知道为解析错误生成有意义的错误消息是非常困难的。事实上，您会发现一种叫做“跳过”的现象，在这种情况下，如果有疑问，词法分析器或语法分析器将试图跳过不正确的代码，直到遇到有意义的东西:这种方法正是静态分析工具所采用的，当用户键入不完整的代码时，静态分析工具有望对其正确工作。

### 使用词法分析器和语法分析器

实现了`lex()`和`parse()`之后，我们最终可以解析表达式并计算其值:

```
1   string input{ "(13-4)-(12+1)" };
2   auto tokens = lex(input);
3   auto parsed = parse(tokens);
4   cout << input << " = " << parsed->eval() << endl;
5   // prints "(13-4)-(12+1) = -4"

```

## 用 Boost 解析。精神

在现实世界中，很少有人用手动解析器来处理复杂的事情。当然，如果您正在解析一种“琐碎的”数据存储格式，比如 XML 或 JSON，那么手工滚动解析器是很容易的。但是如果您正在实现自己的 DSL 或编程语言，这不是一个选项。

助推。Spirit 是一个库，它通过为解析器的构造提供 succint(虽然不是特别直观)API 来帮助创建解析器。该库并不试图明确地将词法分析和解析阶段分开(除非您真的想这样做)，而是允许您定义如何将文本结构映射到您定义的类型的对象上。

让我给你看一些使用 Boost 的例子。tln 编程语言的精神。 [<sup>1</sup>](#Fn1)

### 抽象语法树

首先，您需要 AST(抽象语法树)。在这方面，我简单地创建了一个支持访问者设计模式的基类，因为遍历这些结构非常重要:

```
1   struct ast_element
2   {
3     virtual ~ast_element() = default;
4     virtual void accept(ast_element_visitor& visitor) = 0;
5   };

```

然后，该接口用于在我的语言中定义不同的代码结构，例如:

```
 1   struct property : ast_element
 2   {
 3     vector<wstring> names;
 4     type_specification type;
 5     bool is_constant{ false };
 6     wstring default_value;
 7
 8     void accept(ast_element_visitor& visitor) override

 9     {
10       visitor.visit(*this);
11     }
12   };

```

前面的属性定义有四个不同的部分，每个部分都存储在一个公共可访问的字段中。注意，它使用了一个`type_specification`，它本身就是另一个`ast_element`。

AST 的每一个类都需要适应 Boost。fusion——另一个 Boost 库，支持编译时(元编程)和运行时算法的融合(因此得名)。改编代码非常简单:

```
1   BOOST_FUSION_ADAPT_STRUCT(
2     tlön::property,
3     (std::vector<std::wstring>, names),
4     (tlön::type_specification, type),
5     (bool, is_constant),
6     (std::wstring, default_value)
7   )

```

Spirit 解析成常见的数据类型没有问题，比如一个`std::vector`或`std::optional`。它在多态性方面确实有一些问题:Spirit 更喜欢使用`variant`，而不是让您的 AST 类型相互继承，也就是说:

```
1   typedef variant<function_body, property, function_signature> class_member;

```

### 句法分析程序

助推。Spirit 让我们将解析器定义为一组规则。使用的语法非常类似于正则表达式或 BNF (Bachus-Naur 形式)符号，除了运算符放在符号之前，而不是之后。以下是一个规则示例:

```
1   class_declaration_rule %=
2     lit(L"class ") >> +(alnum) % '.'
3     >> -(lit(L"(") >> -parameter_declaration_rule % ',' >> lit(")"))
4     >> "{"
5     >> *(function_body_rule | property_rule | function_signature_rule)
6     >> "}";

```

前面期望类声明以单词`class`开始。然后它期望一个或多个单词(每个单词是一个或多个字母数字字符，因此是`+(alnum)`)，用句点`'.'`分隔——这就是`%`操作符的用途。您可能已经猜到，结果会映射到一个`vector`上。随后，在花括号之后，我们期望零个或多个函数、属性或函数签名的定义——使用`variant`将这些字段映射到我们之前的定义。

自然，有些元素是 AST 元素整个层次结构的“根”。在我们的例子中，这个根叫做`file`(惊喜！)，这里有一个函数既解析文件又漂亮地打印它:

```
 1   template<typename TLanguagePrinter, typename Iterator>
 2   wstring parse(Iterator first, Iterator last)
 3   {
 4     using spirit::qi::phrase_parse;
 5
 6     file f;
 7     file_parser<wstring::const_iterator> fp{};
 8     auto b = phrase_parse(first, last, fp, space, f);
 9     if (b)
10     {
11       return TLanguagePrinter{}.pretty_print(f);
12     }
13     return wstring(L"FAIL");
14   }

```

前面的类型`TLanguagePrinter`本质上是一个访问者，它知道如何用不同的语言(比如 C++)来呈现我们的 AST。

### 打印机

在解析了语言之后，我们可能想要编译它，或者在我的例子中，将它转换成其他语言。考虑到我们之前已经在整个 AST 层次结构中实现了一个`accept()`方法，这相当容易。

唯一的挑战是如何对待`variant`类型的人，因为他们需要特殊的访客。在`std::variant`的情况下，你要找的是`std::visit()`，但是因为我们用的是`boost::variant`，所以要调用的函数是`boost::accept_visitor()`。这个函数要求你给它一个从`static_visitor`继承的类的实例，并为每一个可能的类型提供函数调用重载。这里有一个例子:

```
 1   struct default_value_visitor : static_visitor<>
 2   {
 3     cpp_printer& printer;
 4
 5     explicit default_value_visitor(cpp_printer& printer)
 6       : printer{printer}
 7     {
 8     }
 9
10     void operator()(const basic_type& bt) const

11     {
12       // for a scalar value, we just dump its default
13       printer.buffer << printer.default_value_for(bt.name);
14     }
15
16     void operator()(const tuple_signature& ts) const

17     {
18       for (auto& e : ts.elements)
19       {
20         this->operator()(e.type);
21         printer.buffer << ", ";
22       }
23       printer.backtrack(2);
24     }
25   };

```

然后调用`accept_visitor(foo, default_value_visitor{...})`，正确的重载将被调用，这取决于实际存储在`variant`中的对象的类型。

## 摘要

首先，需要说明的是，相对而言，解释器设计模式有点不常见——构建解析器的挑战现在被认为是无关紧要的，这就是为什么我看到它在许多英国大学(包括我自己的大学)的计算机科学课程中被删除。此外，除非你打算从事语言设计，或者制作静态代码分析工具，否则你不太可能找到需求量很大的构建解析器的技能。

也就是说，解释的挑战是计算机科学的一个完全独立的领域，一本设计模式书的一章无法合理地公正对待它。如果您对这个主题感兴趣，我建议您查看诸如 Lex/Yacc、ANTLR 等专门针对 lexer/parser 构造的框架。我还可以推荐为流行的 ide 编写静态分析插件——这是一个很好的方式来感受真实的 ASTs 是什么样子的，是如何遍历的，甚至是如何修改的。

Footnotes [1](#Fn1_source)

tln 是一种玩具语言，我构建它是为了演示“如果你不喜欢现有的语言，就构建一种新的语言”的想法。它使用 Boost。Spirit 并交叉编译(transpiles)成 C++。它是开源的，可以在 [`https://github.com/nesteruk/tlon`](https://github.com/nesteruk/tlon) 找到